@article{BKLP-EJS-2020,
 abrjournal = {Electron. J. Stat.},
 abstract = {In this article, we propose a new adaptive estimator for compact supported density functions, in the framework of multivariate mixing processes. Several procedures have been proposed in the literature to tackle the boundary bias issue encountered using classical kernel estimators on the unit d-dimensional hypercube. We extend such results to more general bounded domains in R d. We introduce a specific family of kernel-type estimators adapted to the estimation of compact supported density functions. We then propose a data-driven Goldenshluger and Lepski type procedure to jointly select a kernel and a bandwidth. We prove the optimality of our procedure in the adaptive framework, stating an oracle-type inequality. We illustrate the good behavior of our new class of estimators on simulated data. Finally, we apply our procedure to a real dataset.},
 author = {Bertin, Karine and Klutchnikoff, Nicolas and Léon, Jose R. and Prieur, Clémentine},
 doi = {10.1214/20-EJS1682},
 issn = {1935-7524},
 journal = {Electronic Journal of Statistics},
 keywords = {62G07,62H12,60G10,62P10,92D50},
 language = {English},
 number = {1},
 pages = {2198--2237},
 title = {Adaptive density estimation on bounded domains under mixing conditions},
 volume = {14},
 year = {2020}
}

