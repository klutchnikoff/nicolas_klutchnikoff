@misc{STCKB-ARXIV-2022,
 abstract = {The mathematical forces at work behind Generative Adversarial Networks raise challenging theoretical issues. Motivated by the important question of characterizing the geometrical properties of the generated distributions, we provide a thorough analysis of Wasserstein GANs (WGANs) in both the finite sample and asymptotic regimes. We study the specific case where the latent space is univariate and derive results valid regardless of the dimension of the output space. We show in particular that for a fixed sample size, the optimal WGANs are closely linked with connected paths minimizing the sum of the squared Euclidean distances between the sample points. We also highlight the fact that WGANs are able to approach (for the 1-Wasserstein distance) the target distribution as the sample size tends to infinity, at a given convergence rate and provided the family of generative Lipschitz functions grows appropriately. We derive in passing new results on optimal transport theory in the semi-discrete setting.},
 author = {Stéphanovitch, Arthur and Tanielian, Ugo and Cadre, Benoît and Klutchnikoff, Nicolas and Biau, Gérard},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.2201.02824},
 keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Statistics Theory (math.ST)},
 publisher = {arXiv},
 title = {Optimal 1-Wasserstein Distance for WGANs},
 year = {2022}
}

